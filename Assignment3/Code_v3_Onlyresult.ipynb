{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code v3 Onlyresult.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnJ3PLRsy44o"
      },
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import scale\n",
        "from math import exp\n",
        "from collections import defaultdict \n",
        "from sklearn.metrics.pairwise import chi2_kernel\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTiAayGUzTQc",
        "outputId": "b52e27b3-bd3b-4012-a130-f58a74f4358a"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Google Colab Notebooks/DMW/SVMC Markov/letter-recognition.csv')\n",
        "\n",
        "# feature names were like - 'letter ' changed it to 'letter'\n",
        "df.columns = ['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar',\n",
        "       'ybar', 'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge',\n",
        "       'xedgey', 'yedge', 'yedgex']\n",
        "print(df.columns)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar', 'ybar',\n",
            "       'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge', 'xedgey',\n",
            "       'yedge', 'yedgex'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "-nerPuQPzUxg",
        "outputId": "e0450803-e82e-44d5-d878-383e4514fbba"
      },
      "source": [
        "print(f\"Number of rows = {df.shape[0]}, cols = {df.shape[1]}\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows = 20000, cols = 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>letter</th>\n",
              "      <th>xbox</th>\n",
              "      <th>ybox</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>onpix</th>\n",
              "      <th>xbar</th>\n",
              "      <th>ybar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybar</th>\n",
              "      <th>xy2bar</th>\n",
              "      <th>xedge</th>\n",
              "      <th>xedgey</th>\n",
              "      <th>yedge</th>\n",
              "      <th>yedgex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  letter  xbox  ybox  width  height  ...  xy2bar  xedge  xedgey  yedge  yedgex\n",
              "0      T     2     8      3       5  ...       8      0       8      0       8\n",
              "1      I     5    12      3       7  ...       9      2       8      4      10\n",
              "2      D     4    11      6       8  ...       7      3       7      3       9\n",
              "3      N     7    11      6       6  ...      10      6      10      2       8\n",
              "4      G     2     1      3       1  ...       9      1       7      5      10\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLYVqgJezWLu",
        "outputId": "ec41720a-27f0-454a-c382-3fd071e49843"
      },
      "source": [
        "# number of different classes\n",
        "classes = df['letter'].unique()\n",
        "print(f'Number of different labels in dataset = {len(classes)}')\n",
        "classes.sort()\n",
        "for cls in classes:\n",
        "    rows = len(df[df['letter'] == cls])\n",
        "    print(f'Number of data points in class {cls} = {rows}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different labels in dataset = 26\n",
            "Number of data points in class A = 789\n",
            "Number of data points in class B = 766\n",
            "Number of data points in class C = 736\n",
            "Number of data points in class D = 805\n",
            "Number of data points in class E = 768\n",
            "Number of data points in class F = 775\n",
            "Number of data points in class G = 773\n",
            "Number of data points in class H = 734\n",
            "Number of data points in class I = 755\n",
            "Number of data points in class J = 747\n",
            "Number of data points in class K = 739\n",
            "Number of data points in class L = 761\n",
            "Number of data points in class M = 792\n",
            "Number of data points in class N = 783\n",
            "Number of data points in class O = 753\n",
            "Number of data points in class P = 803\n",
            "Number of data points in class Q = 783\n",
            "Number of data points in class R = 758\n",
            "Number of data points in class S = 748\n",
            "Number of data points in class T = 796\n",
            "Number of data points in class U = 813\n",
            "Number of data points in class V = 764\n",
            "Number of data points in class W = 752\n",
            "Number of data points in class X = 787\n",
            "Number of data points in class Y = 786\n",
            "Number of data points in class Z = 734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P663gXiJ0JuS"
      },
      "source": [
        "def predict(z):\n",
        "  x = zt.loc[:, zt.columns != 'letter']\n",
        "  y = zt.loc[:, zt.columns == 'letter']\n",
        "  # doubtful\n",
        "  fx = f0.predict(x)\n",
        "  return fx"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0YStq2k0MsZ"
      },
      "source": [
        "# returns the loss value calculated using model f0\n",
        "def loss(z):\n",
        "  y = z.iloc[0]['letter']\n",
        "  # doubtful\n",
        "  fx = predict(z)\n",
        "\n",
        "  if fx*y > 1:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1-fx*y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KfXXeTS0M0c"
      },
      "source": [
        "def calculate_P(zs,zst):\n",
        "  P = exp(-loss(zs))/exp(-loss(zt))\n",
        "  return P"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXVqtU_50M7A"
      },
      "source": [
        "def acceptance_prob(zs,zt):\n",
        "  ys = zs.iloc[0]['letter']\n",
        "  yt = zt.iloc[0]['letter']\n",
        "\n",
        "  fs = predict(zs)\n",
        "  ft = predict(zt)\n",
        "\n",
        "  return exp(-fs*ys)/exp(-ft*yt)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSaZjkpE0_0k"
      },
      "source": [
        "def hellinger(X1, X2):\n",
        "  return np.sqrt(np.dot(X1,X2.T))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKMRWmXUzY6N",
        "outputId": "56b404c1-b106-4308-83e3-387617959e9a"
      },
      "source": [
        "avg_acc = {'linear':0, 'rbf':0, 'poly':0, 'chi_squared':0, 'hellinger':0}\n",
        "\n",
        "for alp in classes:\n",
        "    print(f'\\nRunning for alphabet = {alp}')\n",
        "\n",
        "    df1 = df.copy()\n",
        "\n",
        "    alphabet = alp\n",
        "    df1.loc[(df1.letter != alphabet),'letter'] = -1\n",
        "    df1.loc[(df1.letter == alphabet),'letter'] = 1\n",
        "    pos = df1[df1['letter']==1].sample(frac=1)\n",
        "    neg = df1[df1['letter']==-1].sample(frac=1/25)\n",
        "    df_final = pos.append(neg,ignore_index=True)\n",
        "\n",
        "    df_final_train, df_final_test = train_test_split(df_final, test_size=0.3, random_state=42)\n",
        "    M = 1000\n",
        "    N1 = round(M * 0.75)\n",
        "    df_sample = df_final_train.sample(n=N1)\n",
        "    df_sample_features = df_sample.loc[:, df_sample.columns != 'letter']\n",
        "    df_sample_target = df_sample.loc[:, ['letter']]\n",
        "\n",
        "    # df_sample_features = scale(df_sample_features)\n",
        "    df_sample_target = df_sample_target.astype('int')\n",
        "\n",
        "    f0 = SVC(kernel = 'linear')\n",
        "    f0.fit(df_sample_features, df_sample_target.values.ravel())\n",
        "\n",
        "    m_pos, m_neg = 0, 0\n",
        "    zt = df_final_train.sample(n=1)\n",
        "    # print(zt)\n",
        "    if M%2 == 0:\n",
        "        label = zt.iloc[0]['letter']\n",
        "        print(\"\")\n",
        "        if label == 1:\n",
        "            m_pos += 1\n",
        "        else:\n",
        "            m_neg += 1\n",
        "\n",
        "    # Step 3\n",
        "    # should its type be pandas.dataframe?\n",
        "    sampled_data = []\n",
        "    # keep count of how many times a sample is rejected\n",
        "    rejected = defaultdict(int)\n",
        "\n",
        "    # all variable names are as given in paper\n",
        "    # constants used in algorithm, see section 4A point 1 in paper\n",
        "    K = 5\n",
        "    Q = 1.2\n",
        "    while m_pos < M//2 or m_neg < M//2:\n",
        "        # draw one sample randomly = z_star(zs)\n",
        "        zs = df_final_train.sample(n=1)\n",
        "        # print(\"considering \",zs)\n",
        "        P = calculate_P(zs,zt)\n",
        "        \n",
        "        # yt corresponds to Y of zt\n",
        "        yt = zt.iloc[0]['letter']\n",
        "        ys = zs.iloc[0]['letter']\n",
        "\n",
        "        # alpha is the acceptance probability of zs, given in step 5\n",
        "        alpha = P\n",
        "        # need to convert it to tuple so that it becomes hashable\n",
        "        tpl = tuple(zs.to_records(index=False)[0])\n",
        "\n",
        "        if P==1 and yt==-1 and ys==-1:\n",
        "            alpha = acceptance_prob(zs,zt)  # P'\n",
        "        elif P==1 and yt==1 and ys==1:    \n",
        "            alpha = acceptance_prob(zs,zt)  # P'\n",
        "        elif (P==1 and yt*ys==-1) or P<1 :\n",
        "            alpha = P                       # P\n",
        "        elif rejected[tpl]>K:\n",
        "            alpha = QP                      # P''\n",
        "                                \n",
        "        if alpha>1:\n",
        "            alpha=1\n",
        "\n",
        "        # print(f\"alpha {alpha}\")\n",
        "        if np.random.random() < alpha:\n",
        "            sampled_data.append(zs)\n",
        "        else:\n",
        "            rejected[tpl]+=1\n",
        "\n",
        "        if yt == 1:\n",
        "            m_pos += 1 \n",
        "        else:\n",
        "            m_neg += 1\n",
        "        \n",
        "        # for next iteration \n",
        "        zt = zs\n",
        "        # print(f\"Positive = {m_pos} Negative = {m_neg}\")\n",
        "\n",
        "    dataset = pd.concat(sampled_data)\n",
        "    features = dataset.loc[:, dataset.columns != 'letter']\n",
        "    target = dataset.loc[:, ['letter']]\n",
        "\n",
        "    # X_train = scale(features)\n",
        "    X_train = features\n",
        "    y_train = target\n",
        "    y_train = y_train.astype('int')\n",
        "\n",
        "\n",
        "    # X_test = scale(df_final_test.loc[:, df_final_test.columns != 'letter'])\n",
        "    X_test = df_final_test.loc[:, df_final_test.columns != 'letter']\n",
        "    y_test = df_final_test.loc[:, ['letter']]\n",
        "    y_test = y_test.astype('int')\n",
        "\n",
        "\n",
        "    # model training\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    kernels = ['linear', 'rbf', 'poly']\n",
        "    for kernel in kernels:\n",
        "        model = SVC(kernel = kernel)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
        "        print(f\"Kernel = {kernel}, accuracy = {acc * 100}\")\n",
        "        avg_acc[kernel] += acc\n",
        "\n",
        "    model = SVC(kernel = hellinger)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
        "    print(f\"Kernel = hellinger, accuracy = {acc * 100}\")\n",
        "    avg_acc['hellinger'] += acc\n",
        "\n",
        "    model = SVC(kernel = chi2_kernel)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
        "    print(f\"Kernel = chi2_kernel, accuracy = {acc * 100}\")\n",
        "    avg_acc['chi_squared'] += acc\n",
        "\n",
        "print()\n",
        "for item in avg_acc:\n",
        "    val = avg_acc[item] / 26\n",
        "    print(f\"Average accuracy for {item} = {val * 100}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running for alphabet = A\n",
            "\n",
            "Kernel = linear, accuracy = 95.94017094017094\n",
            "Kernel = rbf, accuracy = 97.00854700854701\n",
            "Kernel = poly, accuracy = 99.14529914529915\n",
            "Kernel = hellinger, accuracy = 94.87179487179486\n",
            "Kernel = chi2_kernel, accuracy = 96.15384615384616\n",
            "\n",
            "Running for alphabet = B\n",
            "\n",
            "Kernel = linear, accuracy = 89.80477223427332\n",
            "Kernel = rbf, accuracy = 93.27548806941431\n",
            "Kernel = poly, accuracy = 93.70932754880694\n",
            "Kernel = hellinger, accuracy = 91.3232104121475\n",
            "Kernel = chi2_kernel, accuracy = 96.74620390455532\n",
            "\n",
            "Running for alphabet = C\n",
            "\n",
            "Kernel = linear, accuracy = 92.05298013245033\n",
            "Kernel = rbf, accuracy = 94.48123620309052\n",
            "Kernel = poly, accuracy = 95.14348785871964\n",
            "Kernel = hellinger, accuracy = 90.50772626931567\n",
            "Kernel = chi2_kernel, accuracy = 97.57174392935983\n",
            "\n",
            "Running for alphabet = D\n",
            "\n",
            "Kernel = linear, accuracy = 87.07627118644068\n",
            "Kernel = rbf, accuracy = 92.37288135593221\n",
            "Kernel = poly, accuracy = 93.22033898305084\n",
            "Kernel = hellinger, accuracy = 82.41525423728814\n",
            "Kernel = chi2_kernel, accuracy = 96.39830508474576\n",
            "\n",
            "Running for alphabet = E\n",
            "\n",
            "Kernel = linear, accuracy = 85.06493506493507\n",
            "Kernel = rbf, accuracy = 90.9090909090909\n",
            "Kernel = poly, accuracy = 93.07359307359307\n",
            "Kernel = hellinger, accuracy = 83.11688311688312\n",
            "Kernel = chi2_kernel, accuracy = 96.53679653679653\n",
            "\n",
            "Running for alphabet = F\n",
            "\n",
            "Kernel = linear, accuracy = 89.22413793103449\n",
            "Kernel = rbf, accuracy = 94.82758620689656\n",
            "Kernel = poly, accuracy = 92.88793103448276\n",
            "Kernel = hellinger, accuracy = 88.14655172413794\n",
            "Kernel = chi2_kernel, accuracy = 95.47413793103449\n",
            "\n",
            "Running for alphabet = G\n",
            "\n",
            "Kernel = linear, accuracy = 82.72138228941685\n",
            "Kernel = rbf, accuracy = 90.92872570194385\n",
            "Kernel = poly, accuracy = 88.76889848812095\n",
            "Kernel = hellinger, accuracy = 81.42548596112312\n",
            "Kernel = chi2_kernel, accuracy = 96.32829373650108\n",
            "\n",
            "Running for alphabet = H\n",
            "\n",
            "Kernel = linear, accuracy = 75.4424778761062\n",
            "Kernel = rbf, accuracy = 85.61946902654867\n",
            "Kernel = poly, accuracy = 88.71681415929203\n",
            "Kernel = hellinger, accuracy = 72.56637168141593\n",
            "Kernel = chi2_kernel, accuracy = 90.929203539823\n",
            "\n",
            "Running for alphabet = I\n",
            "\n",
            "Kernel = linear, accuracy = 88.8646288209607\n",
            "Kernel = rbf, accuracy = 96.06986899563319\n",
            "Kernel = poly, accuracy = 97.16157205240175\n",
            "Kernel = hellinger, accuracy = 83.84279475982532\n",
            "Kernel = chi2_kernel, accuracy = 96.94323144104804\n",
            "\n",
            "Running for alphabet = J\n",
            "\n",
            "Kernel = linear, accuracy = 92.54385964912281\n",
            "Kernel = rbf, accuracy = 94.51754385964912\n",
            "Kernel = poly, accuracy = 95.6140350877193\n",
            "Kernel = hellinger, accuracy = 90.35087719298247\n",
            "Kernel = chi2_kernel, accuracy = 97.80701754385966\n",
            "\n",
            "Running for alphabet = K\n",
            "\n",
            "Kernel = linear, accuracy = 87.63796909492274\n",
            "Kernel = rbf, accuracy = 94.26048565121413\n",
            "Kernel = poly, accuracy = 94.26048565121413\n",
            "Kernel = hellinger, accuracy = 84.10596026490066\n",
            "Kernel = chi2_kernel, accuracy = 95.14348785871964\n",
            "\n",
            "Running for alphabet = L\n",
            "\n",
            "Kernel = linear, accuracy = 92.3913043478261\n",
            "Kernel = rbf, accuracy = 95.43478260869566\n",
            "Kernel = poly, accuracy = 95.43478260869566\n",
            "Kernel = hellinger, accuracy = 90.0\n",
            "Kernel = chi2_kernel, accuracy = 96.30434782608695\n",
            "\n",
            "Running for alphabet = M\n",
            "\n",
            "Kernel = linear, accuracy = 97.22222222222221\n",
            "Kernel = rbf, accuracy = 96.15384615384616\n",
            "Kernel = poly, accuracy = 97.22222222222221\n",
            "Kernel = hellinger, accuracy = 95.51282051282051\n",
            "Kernel = chi2_kernel, accuracy = 95.94017094017094\n",
            "\n",
            "Running for alphabet = N\n",
            "\n",
            "Kernel = linear, accuracy = 90.77253218884121\n",
            "Kernel = rbf, accuracy = 93.99141630901288\n",
            "Kernel = poly, accuracy = 94.20600858369099\n",
            "Kernel = hellinger, accuracy = 88.41201716738198\n",
            "Kernel = chi2_kernel, accuracy = 95.27896995708154\n",
            "\n",
            "Running for alphabet = O\n",
            "\n",
            "Kernel = linear, accuracy = 79.64989059080962\n",
            "Kernel = rbf, accuracy = 94.74835886214443\n",
            "Kernel = poly, accuracy = 96.49890590809628\n",
            "Kernel = hellinger, accuracy = 76.58643326039387\n",
            "Kernel = chi2_kernel, accuracy = 98.24945295404814\n",
            "\n",
            "Running for alphabet = P\n",
            "\n",
            "Kernel = linear, accuracy = 91.3135593220339\n",
            "Kernel = rbf, accuracy = 95.12711864406779\n",
            "Kernel = poly, accuracy = 96.1864406779661\n",
            "Kernel = hellinger, accuracy = 90.2542372881356\n",
            "Kernel = chi2_kernel, accuracy = 97.03389830508475\n",
            "\n",
            "Running for alphabet = Q\n",
            "\n",
            "Kernel = linear, accuracy = 87.98283261802575\n",
            "Kernel = rbf, accuracy = 95.06437768240343\n",
            "Kernel = poly, accuracy = 95.49356223175965\n",
            "Kernel = hellinger, accuracy = 86.05150214592274\n",
            "Kernel = chi2_kernel, accuracy = 95.70815450643777\n",
            "\n",
            "Running for alphabet = R\n",
            "\n",
            "Kernel = linear, accuracy = 89.76034858387798\n",
            "Kernel = rbf, accuracy = 94.77124183006535\n",
            "Kernel = poly, accuracy = 92.15686274509804\n",
            "Kernel = hellinger, accuracy = 89.32461873638344\n",
            "Kernel = chi2_kernel, accuracy = 96.29629629629629\n",
            "\n",
            "Running for alphabet = S\n",
            "\n",
            "Kernel = linear, accuracy = 88.37719298245614\n",
            "Kernel = rbf, accuracy = 90.78947368421053\n",
            "Kernel = poly, accuracy = 93.2017543859649\n",
            "Kernel = hellinger, accuracy = 87.06140350877193\n",
            "Kernel = chi2_kernel, accuracy = 97.58771929824562\n",
            "\n",
            "Running for alphabet = T\n",
            "\n",
            "Kernel = linear, accuracy = 89.14893617021276\n",
            "Kernel = rbf, accuracy = 93.82978723404256\n",
            "Kernel = poly, accuracy = 95.74468085106383\n",
            "Kernel = hellinger, accuracy = 85.53191489361703\n",
            "Kernel = chi2_kernel, accuracy = 96.80851063829788\n",
            "\n",
            "Running for alphabet = U\n",
            "\n",
            "Kernel = linear, accuracy = 90.50632911392405\n",
            "Kernel = rbf, accuracy = 94.9367088607595\n",
            "Kernel = poly, accuracy = 96.83544303797468\n",
            "Kernel = hellinger, accuracy = 88.18565400843882\n",
            "Kernel = chi2_kernel, accuracy = 96.41350210970464\n",
            "\n",
            "Running for alphabet = V\n",
            "\n",
            "Kernel = linear, accuracy = 91.95652173913044\n",
            "Kernel = rbf, accuracy = 93.69565217391305\n",
            "Kernel = poly, accuracy = 94.1304347826087\n",
            "Kernel = hellinger, accuracy = 90.0\n",
            "Kernel = chi2_kernel, accuracy = 95.65217391304348\n",
            "\n",
            "Running for alphabet = W\n",
            "\n",
            "Kernel = linear, accuracy = 96.93654266958424\n",
            "Kernel = rbf, accuracy = 97.81181619256017\n",
            "Kernel = poly, accuracy = 97.59299781181619\n",
            "Kernel = hellinger, accuracy = 95.62363238512035\n",
            "Kernel = chi2_kernel, accuracy = 97.81181619256017\n",
            "\n",
            "Running for alphabet = X\n",
            "\n",
            "Kernel = linear, accuracy = 84.79657387580299\n",
            "Kernel = rbf, accuracy = 93.14775160599572\n",
            "Kernel = poly, accuracy = 94.86081370449678\n",
            "Kernel = hellinger, accuracy = 79.87152034261243\n",
            "Kernel = chi2_kernel, accuracy = 97.00214132762312\n",
            "\n",
            "Running for alphabet = Y\n",
            "\n",
            "Kernel = linear, accuracy = 93.57601713062098\n",
            "Kernel = rbf, accuracy = 95.07494646680942\n",
            "Kernel = poly, accuracy = 95.93147751605996\n",
            "Kernel = hellinger, accuracy = 91.86295503211991\n",
            "Kernel = chi2_kernel, accuracy = 96.1456102783726\n",
            "\n",
            "Running for alphabet = Z\n",
            "\n",
            "Kernel = linear, accuracy = 94.69026548672566\n",
            "Kernel = rbf, accuracy = 97.34513274336283\n",
            "Kernel = poly, accuracy = 97.12389380530973\n",
            "Kernel = hellinger, accuracy = 94.91150442477876\n",
            "Kernel = chi2_kernel, accuracy = 97.12389380530973\n",
            "\n",
            "Average accuracy for linear = 89.44056362545876\n",
            "Average accuracy for rbf = 94.08435900153268\n",
            "Average accuracy for poly = 94.78161784444326\n",
            "Average accuracy for chi_squared = 96.36111253879433\n",
            "Average accuracy for hellinger = 87.3793509307043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc1IxEE_1P91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}