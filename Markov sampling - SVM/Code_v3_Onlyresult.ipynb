{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code v3 Onlyresult.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  695k  100  695k    0     0   224k      0  0:00:03  0:00:03 --:--:--  224k\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data -o letter-recognition.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnJ3PLRsy44o"
      },
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import scale\n",
        "from math import exp\n",
        "from collections import defaultdict \n",
        "from sklearn.metrics.pairwise import chi2_kernel\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTiAayGUzTQc",
        "outputId": "b52e27b3-bd3b-4012-a130-f58a74f4358a"
      },
      "source": [
        "df = pd.read_csv('letter-recognition.csv')\n",
        "\n",
        "# feature names were like - 'letter ' changed it to 'letter'\n",
        "df.columns = ['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar',\n",
        "       'ybar', 'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge',\n",
        "       'xedgey', 'yedge', 'yedgex']\n",
        "print(df.columns)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar', 'ybar',\n       'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge', 'xedgey',\n       'yedge', 'yedgex'],\n      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "-nerPuQPzUxg",
        "outputId": "e0450803-e82e-44d5-d878-383e4514fbba"
      },
      "source": [
        "print(f\"Number of rows = {df.shape[0]}, cols = {df.shape[1]}\")\n",
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows = 19999, cols = 17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
              "0      I     5    12      3       7      2    10     5      5      4     13   \n",
              "1      D     4    11      6       8      6    10     6      2      6     10   \n",
              "2      N     7    11      6       6      3     5     9      4      6      4   \n",
              "3      G     2     1      3       1      1     8     6      6      6      6   \n",
              "4      S     4    11      5       8      3     8     8      6      9      5   \n",
              "\n",
              "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
              "0       3       9      2       8      4      10  \n",
              "1       3       7      3       7      3       9  \n",
              "2       4      10      6      10      2       8  \n",
              "3       5       9      1       7      5      10  \n",
              "4       6       6      0       8      9       7  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>letter</th>\n      <th>xbox</th>\n      <th>ybox</th>\n      <th>width</th>\n      <th>height</th>\n      <th>onpix</th>\n      <th>xbar</th>\n      <th>ybar</th>\n      <th>x2bar</th>\n      <th>y2bar</th>\n      <th>xybar</th>\n      <th>x2ybar</th>\n      <th>xy2bar</th>\n      <th>xedge</th>\n      <th>xedgey</th>\n      <th>yedge</th>\n      <th>yedgex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I</td>\n      <td>5</td>\n      <td>12</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>13</td>\n      <td>3</td>\n      <td>9</td>\n      <td>2</td>\n      <td>8</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D</td>\n      <td>4</td>\n      <td>11</td>\n      <td>6</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>2</td>\n      <td>6</td>\n      <td>10</td>\n      <td>3</td>\n      <td>7</td>\n      <td>3</td>\n      <td>7</td>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>N</td>\n      <td>7</td>\n      <td>11</td>\n      <td>6</td>\n      <td>6</td>\n      <td>3</td>\n      <td>5</td>\n      <td>9</td>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>10</td>\n      <td>6</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>G</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>7</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>S</td>\n      <td>4</td>\n      <td>11</td>\n      <td>5</td>\n      <td>8</td>\n      <td>3</td>\n      <td>8</td>\n      <td>8</td>\n      <td>6</td>\n      <td>9</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0</td>\n      <td>8</td>\n      <td>9</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLYVqgJezWLu",
        "outputId": "ec41720a-27f0-454a-c382-3fd071e49843"
      },
      "source": [
        "# number of different classes\n",
        "classes = df['letter'].unique()\n",
        "print(f'Number of different labels in dataset = {len(classes)}')\n",
        "classes.sort()\n",
        "for cls in classes:\n",
        "    rows = len(df[df['letter'] == cls])\n",
        "    print(f'Number of data points in class {cls} = {rows}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different labels in dataset = 26\n",
            "Number of data points in class A = 789\n",
            "Number of data points in class B = 766\n",
            "Number of data points in class C = 736\n",
            "Number of data points in class D = 805\n",
            "Number of data points in class E = 768\n",
            "Number of data points in class F = 775\n",
            "Number of data points in class G = 773\n",
            "Number of data points in class H = 734\n",
            "Number of data points in class I = 755\n",
            "Number of data points in class J = 747\n",
            "Number of data points in class K = 739\n",
            "Number of data points in class L = 761\n",
            "Number of data points in class M = 792\n",
            "Number of data points in class N = 783\n",
            "Number of data points in class O = 753\n",
            "Number of data points in class P = 803\n",
            "Number of data points in class Q = 783\n",
            "Number of data points in class R = 758\n",
            "Number of data points in class S = 748\n",
            "Number of data points in class T = 795\n",
            "Number of data points in class U = 813\n",
            "Number of data points in class V = 764\n",
            "Number of data points in class W = 752\n",
            "Number of data points in class X = 787\n",
            "Number of data points in class Y = 786\n",
            "Number of data points in class Z = 734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P663gXiJ0JuS"
      },
      "source": [
        "def predict(z):\n",
        "  x = zt.loc[:, zt.columns != 'letter']\n",
        "  y = zt.loc[:, zt.columns == 'letter']\n",
        "  # doubtful\n",
        "  fx = f0.decision_function(x)/w_norm\n",
        "  return fx[0]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0YStq2k0MsZ"
      },
      "source": [
        "# returns the loss value calculated using model f0\n",
        "def loss(z):\n",
        "  y = z.iloc[0]['letter']\n",
        "  # doubtful\n",
        "  fx = predict(z)\n",
        "\n",
        "  if fx*y > 1:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1-fx*y"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KfXXeTS0M0c"
      },
      "source": [
        "def calculate_P(zs,zst):\n",
        "  P = exp(-loss(zs))/exp(-loss(zt))\n",
        "  return P"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXVqtU_50M7A"
      },
      "source": [
        "def acceptance_prob(zs,zt):\n",
        "  ys = zs.iloc[0]['letter']\n",
        "  yt = zt.iloc[0]['letter']\n",
        "\n",
        "  fs = predict(zs)\n",
        "  ft = predict(zt)\n",
        "\n",
        "  return exp(-fs*ys)/exp(-ft*yt)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSaZjkpE0_0k"
      },
      "source": [
        "def hellinger(X1, X2):\n",
        "  return np.sqrt(np.dot(X1,X2.T))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKMRWmXUzY6N",
        "outputId": "56b404c1-b106-4308-83e3-387617959e9a"
      },
      "source": [
        "avg_acc = {'linear':0, 'rbf':0, 'poly':0, 'chi_squared':0, 'hellinger':0}\n",
        "\n",
        "for alp in classes:\n",
        "    print(f'\\nRunning for alphabet = {alp}')\n",
        "\n",
        "    df1 = df.copy()\n",
        "\n",
        "    alphabet = alp\n",
        "    df1.loc[(df1.letter != alphabet),'letter'] = -1\n",
        "    df1.loc[(df1.letter == alphabet),'letter'] = 1\n",
        "    pos = df1[df1['letter']==1].sample(frac=1)\n",
        "    neg = df1[df1['letter']==-1].sample(frac=1/25)\n",
        "    df_final = pos.append(neg,ignore_index=True)\n",
        "\n",
        "    df_final_train, df_final_test = train_test_split(df_final, test_size=0.3, random_state=42)\n",
        "    M = 1000\n",
        "    N1 = round(M * 0.75)\n",
        "    df_sample = df_final_train.sample(n=N1)\n",
        "    df_sample_features = df_sample.loc[:, df_sample.columns != 'letter']\n",
        "    df_sample_target = df_sample.loc[:, ['letter']]\n",
        "\n",
        "    # df_sample_features = scale(df_sample_features)\n",
        "    df_sample_target = df_sample_target.astype('int')\n",
        "\n",
        "    f0 = SVC(kernel = 'linear')\n",
        "    f0.fit(df_sample_features, df_sample_target.values.ravel())\n",
        "    w_norm = np.linalg.norm(f0.coef_) \n",
        "\n",
        "    m_pos, m_neg = 0, 0\n",
        "    zt = df_final_train.sample(n=1)\n",
        "    # print(zt)\n",
        "    if M%2 == 0:\n",
        "        label = zt.iloc[0]['letter']\n",
        "        print(\"\")\n",
        "        if label == 1:\n",
        "            m_pos += 1\n",
        "        else:\n",
        "            m_neg += 1\n",
        "\n",
        "    # Step 3\n",
        "    # should its type be pandas.dataframe?\n",
        "    sampled_data = []\n",
        "    # keep count of how many times a sample is rejected\n",
        "    rejected = defaultdict(int)\n",
        "\n",
        "    # all variable names are as given in paper\n",
        "    # constants used in algorithm, see section 4A point 1 in paper\n",
        "    K = 5\n",
        "    Q = 1.2\n",
        "    while m_pos < M//2 or m_neg < M//2:\n",
        "        # draw one sample randomly = z_star(zs)\n",
        "        zs = df_final_train.sample(n=1)\n",
        "        # print(\"considering \",zs)\n",
        "        P = calculate_P(zs,zt)\n",
        "        \n",
        "        # yt corresponds to Y of zt\n",
        "        yt = zt.iloc[0]['letter']\n",
        "        ys = zs.iloc[0]['letter']\n",
        "\n",
        "        # alpha is the acceptance probability of zs, given in step 5\n",
        "        alpha = P\n",
        "        # need to convert it to tuple so that it becomes hashable\n",
        "        tpl = tuple(zs.to_records(index=False)[0])\n",
        "\n",
        "        if P==1 and yt==-1 and ys==-1:\n",
        "            alpha = acceptance_prob(zs,zt)  # P'\n",
        "        elif P==1 and yt==1 and ys==1:    \n",
        "            alpha = acceptance_prob(zs,zt)  # P'\n",
        "        elif (P==1 and yt*ys==-1) or P<1 :\n",
        "            alpha = P                       # P\n",
        "        elif rejected[tpl]>K:\n",
        "            alpha = Q*P                      # P''\n",
        "                                \n",
        "        if alpha>1:\n",
        "            alpha=1\n",
        "\n",
        "        # print(f\"alpha {alpha}\")\n",
        "        if np.random.random() < alpha:\n",
        "            sampled_data.append(zs)\n",
        "        else:\n",
        "            rejected[tpl]+=1\n",
        "\n",
        "        if yt == 1:\n",
        "            m_pos += 1 \n",
        "        else:\n",
        "            m_neg += 1\n",
        "        \n",
        "        # for next iteration \n",
        "        zt = zs\n",
        "        # print(f\"Positive = {m_pos} Negative = {m_neg}\")\n",
        "\n",
        "    dataset = pd.concat(sampled_data)\n",
        "    features = dataset.loc[:, dataset.columns != 'letter']\n",
        "    target = dataset.loc[:, ['letter']]\n",
        "\n",
        "    # X_train = scale(features)\n",
        "    X_train = features\n",
        "    y_train = target\n",
        "    y_train = y_train.astype('int')\n",
        "\n",
        "\n",
        "    # X_test = scale(df_final_test.loc[:, df_final_test.columns != 'letter'])\n",
        "    X_test = df_final_test.loc[:, df_final_test.columns != 'letter']\n",
        "    y_test = df_final_test.loc[:, ['letter']]\n",
        "    y_test = y_test.astype('int')\n",
        "\n",
        "\n",
        "    # model training\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    kernels = ['linear', 'rbf', 'poly']\n",
        "    for kernel in kernels:\n",
        "        model = SVC(kernel = kernel)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
        "        print(f\"Kernel = {kernel}, accuracy = {acc * 100}\")\n",
        "        avg_acc[kernel] += acc\n",
        "\n",
        "    model = SVC(kernel = hellinger)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
        "    print(f\"Kernel = hellinger, accuracy = {acc * 100}\")\n",
        "    avg_acc['hellinger'] += acc\n",
        "\n",
        "    model = SVC(kernel = chi2_kernel)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
        "    print(f\"Kernel = chi2_kernel, accuracy = {acc * 100}\")\n",
        "    avg_acc['chi_squared'] += acc\n",
        "\n",
        "print()\n",
        "for item in avg_acc:\n",
        "    val = avg_acc[item] / 26\n",
        "    print(f\"Average accuracy for {item} = {val * 100}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running for alphabet = A\n",
            "\n",
            "Kernel = linear, accuracy = 95.08547008547008\n",
            "Kernel = rbf, accuracy = 95.51282051282051\n",
            "Kernel = poly, accuracy = 95.72649572649573\n",
            "Kernel = hellinger, accuracy = 93.58974358974359\n",
            "Kernel = chi2_kernel, accuracy = 95.08547008547008\n",
            "\n",
            "Running for alphabet = B\n",
            "\n",
            "Kernel = linear, accuracy = 90.67245119305856\n",
            "Kernel = rbf, accuracy = 93.70932754880694\n",
            "Kernel = poly, accuracy = 95.66160520607376\n",
            "Kernel = hellinger, accuracy = 88.28633405639913\n",
            "Kernel = chi2_kernel, accuracy = 96.31236442516268\n",
            "\n",
            "Running for alphabet = C\n",
            "\n",
            "Kernel = linear, accuracy = 90.50772626931567\n",
            "Kernel = rbf, accuracy = 94.03973509933775\n",
            "Kernel = poly, accuracy = 92.27373068432672\n",
            "Kernel = hellinger, accuracy = 90.06622516556291\n",
            "Kernel = chi2_kernel, accuracy = 96.68874172185431\n",
            "\n",
            "Running for alphabet = D\n",
            "\n",
            "Kernel = linear, accuracy = 90.67796610169492\n",
            "Kernel = rbf, accuracy = 95.12711864406779\n",
            "Kernel = poly, accuracy = 95.12711864406779\n",
            "Kernel = hellinger, accuracy = 87.71186440677965\n",
            "Kernel = chi2_kernel, accuracy = 97.88135593220339\n",
            "\n",
            "Running for alphabet = E\n",
            "\n",
            "Kernel = linear, accuracy = 90.9090909090909\n",
            "Kernel = rbf, accuracy = 91.77489177489177\n",
            "Kernel = poly, accuracy = 93.72294372294373\n",
            "Kernel = hellinger, accuracy = 88.74458874458875\n",
            "Kernel = chi2_kernel, accuracy = 97.40259740259741\n",
            "\n",
            "Running for alphabet = F\n",
            "\n",
            "Kernel = linear, accuracy = 86.63793103448276\n",
            "Kernel = rbf, accuracy = 93.10344827586206\n",
            "Kernel = poly, accuracy = 92.88793103448276\n",
            "Kernel = hellinger, accuracy = 85.99137931034483\n",
            "Kernel = chi2_kernel, accuracy = 96.33620689655173\n",
            "\n",
            "Running for alphabet = G\n",
            "\n",
            "Kernel = linear, accuracy = 84.01727861771057\n",
            "Kernel = rbf, accuracy = 88.98488120950324\n",
            "Kernel = poly, accuracy = 89.8488120950324\n",
            "Kernel = hellinger, accuracy = 81.20950323974083\n",
            "Kernel = chi2_kernel, accuracy = 94.38444924406048\n",
            "\n",
            "Running for alphabet = H\n",
            "\n",
            "Kernel = linear, accuracy = 76.32743362831859\n",
            "Kernel = rbf, accuracy = 84.7345132743363\n",
            "Kernel = poly, accuracy = 87.61061946902655\n",
            "Kernel = hellinger, accuracy = 69.02654867256636\n",
            "Kernel = chi2_kernel, accuracy = 92.2566371681416\n",
            "\n",
            "Running for alphabet = I\n",
            "\n",
            "Kernel = linear, accuracy = 85.80786026200873\n",
            "Kernel = rbf, accuracy = 92.79475982532752\n",
            "Kernel = poly, accuracy = 93.88646288209607\n",
            "Kernel = hellinger, accuracy = 80.13100436681223\n",
            "Kernel = chi2_kernel, accuracy = 97.37991266375546\n",
            "\n",
            "Running for alphabet = J\n",
            "\n",
            "Kernel = linear, accuracy = 92.54385964912281\n",
            "Kernel = rbf, accuracy = 94.51754385964912\n",
            "Kernel = poly, accuracy = 96.27192982456141\n",
            "Kernel = hellinger, accuracy = 91.22807017543859\n",
            "Kernel = chi2_kernel, accuracy = 97.36842105263158\n",
            "\n",
            "Running for alphabet = K\n",
            "\n",
            "Kernel = linear, accuracy = 87.41721854304636\n",
            "Kernel = rbf, accuracy = 92.49448123620309\n",
            "Kernel = poly, accuracy = 94.48123620309052\n",
            "Kernel = hellinger, accuracy = 82.560706401766\n",
            "Kernel = chi2_kernel, accuracy = 94.70198675496688\n",
            "\n",
            "Running for alphabet = L\n",
            "\n",
            "Kernel = linear, accuracy = 90.65217391304347\n",
            "Kernel = rbf, accuracy = 95.21739130434783\n",
            "Kernel = poly, accuracy = 93.91304347826087\n",
            "Kernel = hellinger, accuracy = 90.43478260869566\n",
            "Kernel = chi2_kernel, accuracy = 95.0\n",
            "\n",
            "Running for alphabet = M\n",
            "\n",
            "Kernel = linear, accuracy = 96.15384615384616\n",
            "Kernel = rbf, accuracy = 96.15384615384616\n",
            "Kernel = poly, accuracy = 97.64957264957265\n",
            "Kernel = hellinger, accuracy = 95.08547008547008\n",
            "Kernel = chi2_kernel, accuracy = 97.00854700854701\n",
            "\n",
            "Running for alphabet = N\n",
            "\n",
            "Kernel = linear, accuracy = 90.77253218884121\n",
            "Kernel = rbf, accuracy = 92.7038626609442\n",
            "Kernel = poly, accuracy = 92.4892703862661\n",
            "Kernel = hellinger, accuracy = 87.76824034334764\n",
            "Kernel = chi2_kernel, accuracy = 95.27896995708154\n",
            "\n",
            "Running for alphabet = O\n",
            "\n",
            "Kernel = linear, accuracy = 80.52516411378556\n",
            "Kernel = rbf, accuracy = 91.02844638949672\n",
            "Kernel = poly, accuracy = 92.77899343544857\n",
            "Kernel = hellinger, accuracy = 77.4617067833698\n",
            "Kernel = chi2_kernel, accuracy = 94.74835886214443\n",
            "\n",
            "Running for alphabet = P\n",
            "\n",
            "Kernel = linear, accuracy = 92.37288135593221\n",
            "Kernel = rbf, accuracy = 95.55084745762711\n",
            "Kernel = poly, accuracy = 95.12711864406779\n",
            "Kernel = hellinger, accuracy = 90.67796610169492\n",
            "Kernel = chi2_kernel, accuracy = 96.82203389830508\n",
            "\n",
            "Running for alphabet = Q\n",
            "\n",
            "Kernel = linear, accuracy = 87.33905579399142\n",
            "Kernel = rbf, accuracy = 96.35193133047211\n",
            "Kernel = poly, accuracy = 96.13733905579399\n",
            "Kernel = hellinger, accuracy = 82.83261802575107\n",
            "Kernel = chi2_kernel, accuracy = 95.27896995708154\n",
            "\n",
            "Running for alphabet = R\n",
            "\n",
            "Kernel = linear, accuracy = 87.58169934640523\n",
            "Kernel = rbf, accuracy = 93.68191721132898\n",
            "Kernel = poly, accuracy = 94.33551198257081\n",
            "Kernel = hellinger, accuracy = 86.27450980392157\n",
            "Kernel = chi2_kernel, accuracy = 96.51416122004358\n",
            "\n",
            "Running for alphabet = S\n",
            "\n",
            "Kernel = linear, accuracy = 86.40350877192982\n",
            "Kernel = rbf, accuracy = 90.78947368421053\n",
            "Kernel = poly, accuracy = 92.10526315789474\n",
            "Kernel = hellinger, accuracy = 84.86842105263158\n",
            "Kernel = chi2_kernel, accuracy = 95.6140350877193\n",
            "\n",
            "Running for alphabet = T\n",
            "\n",
            "Kernel = linear, accuracy = 91.25799573560768\n",
            "Kernel = rbf, accuracy = 95.3091684434968\n",
            "Kernel = poly, accuracy = 95.94882729211088\n",
            "Kernel = hellinger, accuracy = 86.14072494669509\n",
            "Kernel = chi2_kernel, accuracy = 96.16204690831557\n",
            "\n",
            "Running for alphabet = U\n",
            "\n",
            "Kernel = linear, accuracy = 92.82700421940928\n",
            "Kernel = rbf, accuracy = 97.8902953586498\n",
            "Kernel = poly, accuracy = 98.73417721518987\n",
            "Kernel = hellinger, accuracy = 91.77215189873418\n",
            "Kernel = chi2_kernel, accuracy = 97.46835443037975\n",
            "\n",
            "Running for alphabet = V\n",
            "\n",
            "Kernel = linear, accuracy = 90.43478260869566\n",
            "Kernel = rbf, accuracy = 92.17391304347827\n",
            "Kernel = poly, accuracy = 94.56521739130434\n",
            "Kernel = hellinger, accuracy = 88.91304347826086\n",
            "Kernel = chi2_kernel, accuracy = 96.73913043478261\n",
            "\n",
            "Running for alphabet = W\n",
            "\n",
            "Kernel = linear, accuracy = 96.2800875273523\n",
            "Kernel = rbf, accuracy = 96.93654266958424\n",
            "Kernel = poly, accuracy = 96.93654266958424\n",
            "Kernel = hellinger, accuracy = 95.62363238512035\n",
            "Kernel = chi2_kernel, accuracy = 97.81181619256017\n",
            "\n",
            "Running for alphabet = X\n",
            "\n",
            "Kernel = linear, accuracy = 85.4389721627409\n",
            "Kernel = rbf, accuracy = 93.79014989293361\n",
            "Kernel = poly, accuracy = 90.79229122055675\n",
            "Kernel = hellinger, accuracy = 82.01284796573876\n",
            "Kernel = chi2_kernel, accuracy = 97.4304068522484\n",
            "\n",
            "Running for alphabet = Y\n",
            "\n",
            "Kernel = linear, accuracy = 94.21841541755889\n",
            "Kernel = rbf, accuracy = 94.00428265524626\n",
            "Kernel = poly, accuracy = 95.07494646680942\n",
            "Kernel = hellinger, accuracy = 92.93361884368309\n",
            "Kernel = chi2_kernel, accuracy = 95.07494646680942\n",
            "\n",
            "Running for alphabet = Z\n",
            "\n",
            "Kernel = linear, accuracy = 96.68141592920354\n",
            "Kernel = rbf, accuracy = 97.56637168141593\n",
            "Kernel = poly, accuracy = 97.12389380530973\n",
            "Kernel = hellinger, accuracy = 95.13274336283186\n",
            "Kernel = chi2_kernel, accuracy = 98.23008849557522\n",
            "\n",
            "Average accuracy for linear = 89.59783928967934\n",
            "Average accuracy for rbf = 93.6900754306879\n",
            "Average accuracy for poly = 94.27734209011301\n",
            "Average accuracy for chi_squared = 96.19153881226879\n",
            "Average accuracy for hellinger = 87.17224791598807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc1IxEE_1P91"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}